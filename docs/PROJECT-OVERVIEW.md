# Projeto de AutomaÃ§Ã£o VMware - VisÃ£o Geral Completa

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral do Projeto](#visÃ£o-geral-do-projeto)
2. [DecisÃµes de Arquitetura](#decisÃµes-de-arquitetura)
3. [Estrutura do Projeto](#estrutura-do-projeto)
4. [Fluxo de Trabalho](#fluxo-de-trabalho)
5. [Componentes Principais](#componentes-principais)
6. [ConfiguraÃ§Ã£o e Uso](#configuraÃ§Ã£o-e-uso)
7. [Casos de Uso](#casos-de-uso)

---

## ğŸ¯ VisÃ£o Geral do Projeto

Este projeto fornece automaÃ§Ã£o completa para provisionamento de mÃ¡quinas virtuais (VMs) no ambiente VMware vSphere da TAP, utilizando Terraform, Ansible e scripts shell.

### CaracterÃ­sticas Principais

- âœ… **CriaÃ§Ã£o de VMs sem templates**: VMs sÃ£o criadas do zero usando apenas `guest_id`
- âœ… **Multi-CPD**: Suporta deployment em CPD1, CPD2 ou ambos simultaneamente
- âœ… **CÃ¡lculo automÃ¡tico de instance**: Instance numbers calculados automaticamente (CPD1=Ã­mpar, CPD2=par)
- âœ… **MÃºltiplas VMs**: CriaÃ§Ã£o de vÃ¡rias VMs de uma vez com configuraÃ§Ã£o consistente
- âœ… **SeleÃ§Ã£o de ESXi**: Suporta DRS automÃ¡tico, manual ou seleÃ§Ã£o inteligente por recursos
- âœ… **Nomenclatura padronizada**: `<PURPOSE><ENVIRONMENT><INSTANCE>` (ex: IACTST01, WEBPRD02)
- âœ… **Backend Azure**: State armazenado em Azure Storage Account
- âœ… **SegregaÃ§Ã£o por ambiente**: ConfiguraÃ§Ãµes isoladas para tst, qlt, prd

---

## ğŸ—ï¸ DecisÃµes de Arquitetura

### 1. **Sem Templates VMware**

**DecisÃ£o**: VMs criadas do zero usando `guest_id` ao invÃ©s de clonar templates.

**RazÃ£o**:

- **Simplicidade**: Elimina dependÃªncia de templates prÃ©-configurados no vCenter
- **Flexibilidade**: Permite criar qualquer tipo de VM sem manter templates atualizados
- **ManutenÃ§Ã£o reduzida**: NÃ£o Ã© necessÃ¡rio gerenciar templates em mÃºltiplos vCenters
- **Provisionamento pÃ³s-deploy**: ConfiguraÃ§Ã£o real acontece via Ansible apÃ³s criaÃ§Ã£o

**ImplementaÃ§Ã£o**:

```hcl
# Sem data source de template
# data "vsphere_virtual_machine" "template" { ... }  âŒ

# Apenas guest_id
resource "vsphere_virtual_machine" "vm" {
  guest_id = var.guest_id  # rhel9_64Guest, windows2019srvNext_64Guest
  ...
}
```

**Guest IDs suportados**:

- Linux: `rhel9_64Guest`, `centos8_64Guest`, `ubuntu64Guest`
- Windows: `windows2019srvNext_64Guest`, `windows2022srvNext_64Guest`

---

### 2. **ConfiguraÃ§Ã£o Baseada em CPD**

**DecisÃ£o**: Toda infraestrutura (datacenter, cluster, network) Ã© derivada automaticamente da seleÃ§Ã£o de CPD.

**RazÃ£o**:

- **ConsistÃªncia**: Garante que recursos corretos sejam usados em cada datacenter
- **Simplicidade**: UsuÃ¡rio sÃ³ precisa especificar `cpd = "cpd1"` ou `cpd = "cpd2"`
- **PrevenÃ§Ã£o de erros**: ImpossÃ­vel misturar recursos de CPDs diferentes

**ImplementaÃ§Ã£o**:

```hcl
locals {
  cpd_config = {
    cpd1 = {
      datacenter = "TAP_CPD1"
      cluster    = "CPD1_ESX7"
      network    = "AUTOMTNPRD (LAN-CPD1)"
    }
    cpd2 = {
      datacenter = "TAP_CPD2"
      cluster    = "CPD2_ESX7"
      network    = "AUTOMTNPRD (LAN-CPD2)"
    }
  }
}

# Uso no mÃ³dulo
datacenter = coalesce(var.vsphere_datacenter, local.cpd_config[each.value.cpd].datacenter)
```

**Overrides possÃ­veis**: VariÃ¡veis `vsphere_datacenter`, `vsphere_cluster`, `vsphere_network` podem sobrescrever valores padrÃ£o.

---

### 3. **CÃ¡lculo AutomÃ¡tico de Instance Number**

**DecisÃ£o**: Instance number NÃƒO Ã© variÃ¡vel em `terraform.tfvars` - Ã© calculado automaticamente baseado em CPD e sequÃªncia.

**RazÃ£o**:

- **PrevenÃ§Ã£o de conflitos**: ImpossÃ­vel criar VMs com mesmo instance number em CPDs diferentes
- **Paridade garantida**: CPD1 sempre Ã­mpar (01, 03, 05...), CPD2 sempre par (02, 04, 06...)
- **ReplicaÃ§Ã£o consistente**: Ao usar `cpd = "both"`, mesma sequÃªncia gera pares corretos

**ImplementaÃ§Ã£o**:

```hcl
# CÃ¡lculo da instance number
instance_number = each.value.cpd == "cpd1" ? (each.value.sequence * 2 - 1) : (each.value.sequence * 2)

# Exemplos:
# CPD1, sequence=1 â†’ instance=01
# CPD2, sequence=1 â†’ instance=02
# CPD1, sequence=2 â†’ instance=03
# CPD2, sequence=2 â†’ instance=04
```

**VariÃ¡veis no tfvars**:

```hcl
linux_vm_count = 3              # Quantas VMs criar
linux_vm_start_sequence = 1     # ComeÃ§ar na sequÃªncia 1
# Resultado: VMs com sequences 1, 2, 3 â†’ instances 01, 03, 05 (CPD1) ou 02, 04, 06 (CPD2)
```

---

### 4. **Multi-CPD Deployment**

**DecisÃ£o**: Suporte para criar VMs em ambos CPDs simultaneamente com mesma configuraÃ§Ã£o.

**RazÃ£o**:

- **High Availability**: VMs pares para redundÃ¢ncia
- **Disaster Recovery**: Infra replicada em dois datacenters
- **EficiÃªncia**: Uma Ãºnica execuÃ§Ã£o cria tudo

**ImplementaÃ§Ã£o**:

```hcl
# Determinar CPDs alvo
locals {
  target_cpds = var.cpd == "both" ? ["cpd1", "cpd2"] : [var.cpd]
}

# Criar mapa de VMs para todos os CPDs
linux_vms = {
  for item in flatten([
    for cpd in local.target_cpds : [
      for idx in range(var.linux_vm_count) : {
        cpd      = cpd
        sequence = var.linux_vm_start_sequence + idx
      }
    ]
  ]) : "${item.cpd}-${item.sequence}" => item
}
```

**Exemplo prÃ¡tico**:

```hcl
cpd = "both"
linux_vm_count = 2
linux_vm_start_sequence = 1
linux_vm_purpose = "web"
environment = "prd"

# Resultado:
# CPD1: WEBPRD01 (sequence=1, instance=01)
# CPD1: WEBPRD03 (sequence=2, instance=03)
# CPD2: WEBPRD02 (sequence=1, instance=02)
# CPD2: WEBPRD04 (sequence=2, instance=04)
```

---

### 5. **MÃºltiplas VMs com ConfiguraÃ§Ã£o Consistente**

**DecisÃ£o**: Usar `vm_count` e `vm_start_sequence` para criar mÃºltiplas VMs, nÃ£o variÃ¡veis individuais por VM.

**RazÃ£o**:

- **EficiÃªncia**: Criar 10 VMs com mesma config sem repetir cÃ³digo
- **ConsistÃªncia**: Todas VMs compartilham mesmos recursos (CPU, memÃ³ria, disco)
- **ManutenÃ§Ã£o**: Alterar config afeta todas VMs simultaneamente

**ImplementaÃ§Ã£o**:

```hcl
# Ao invÃ©s de:
# linux_instance_1 = {...}
# linux_instance_2 = {...}

# Usar:
linux_vm_count = 5
linux_vm_start_sequence = 10
# Cria VMs com sequences: 10, 11, 12, 13, 14
```

**Limites de validaÃ§Ã£o**:

- `vm_count`: 1 a 10 VMs por execuÃ§Ã£o
- `vm_start_sequence`: 1 a 90 (permite atÃ© 90 VMs no total com sequÃªncias diferentes)

---

### 6. **For_Each ao invÃ©s de Count**

**DecisÃ£o**: Usar `for_each` baseado em maps, nÃ£o `count` baseado em Ã­ndices.

**RazÃ£o**:

- **Flexibilidade**: Adicionar/remover VMs especÃ­ficas sem afetar outras
- **IdentificaÃ§Ã£o**: VMs identificadas por chaves significativas (`cpd1-1`, `cpd2-3`)
- **MudanÃ§as targeted**: `terraform destroy -target=module.linux_vm["cpd1-2"]`
- **Evita reordenaÃ§Ã£o**: Remover VM do meio nÃ£o recria as seguintes

**ImplementaÃ§Ã£o**:

```hcl
# Mapa de VMs
linux_vms = {
  "cpd1-1" => { cpd = "cpd1", sequence = 1, vm_index = 0 }
  "cpd1-2" => { cpd = "cpd1", sequence = 2, vm_index = 1 }
  "cpd2-1" => { cpd = "cpd2", sequence = 1, vm_index = 0 }
}

# For_each no mÃ³dulo
module "linux_vm" {
  for_each = local.linux_vms
  source   = "./terraform-modules/linux"
  
  vm_name = module.linux_naming[each.key].vm_name
  ...
}
```

---

### 7. **SeleÃ§Ã£o de ESXi Host**

**DecisÃ£o**: TrÃªs opÃ§Ãµes de seleÃ§Ã£o de host, sendo DRS o padrÃ£o.

**RazÃ£o**:

- **DRS padrÃ£o**: VMware DRS geralmente toma boas decisÃµes
- **Manual quando necessÃ¡rio**: Alguns casos requerem host especÃ­fico
- **AutomÃ¡tico inteligente**: Script Python seleciona host com mais recursos disponÃ­veis

**OpÃ§Ãµes disponÃ­veis**:

#### OpÃ§Ã£o 1: DRS AutomÃ¡tico (PadrÃ£o)

```hcl
vsphere_esx_host = null  # ou nÃ£o definir
```

VMware DRS escolhe automaticamente baseado em balanceamento de carga.

#### OpÃ§Ã£o 2: Manual

```hcl
vsphere_esx_host = "esxprd109.tapnet.tap.pt"
```

VM serÃ¡ criada no host especificado.

#### OpÃ§Ã£o 3: Auto-Select via Script

```bash
export TF_VAR_vsphere_esx_host=$(bash scripts/auto-select-esx.sh CPD1_ESX7 TAP_CPD1)
```

**Script Python** (`select-best-esx-host.py`):

- Conecta ao vCenter via pyvmomi
- Lista todos hosts no cluster
- Filtra: connected, powered on, not in maintenance
- Calcula recursos disponÃ­veis:
  - CPU: Total MHz - Used MHz
  - Memory: Total MB - Used MB
- Seleciona baseado em mÃ©trica:
  - `cpu`: Mais CPU disponÃ­vel
  - `memory`: Mais memÃ³ria disponÃ­vel
  - `balanced`: Melhor balanceamento (padrÃ£o)

---

### 8. **Gerenciamento de Discos**

**DecisÃ£o**: Discos adicionais configurados no resource da VM, nÃ£o em mÃ³dulo separado.

**RazÃ£o**:

- **LimitaÃ§Ã£o do provider**: vSphere provider nÃ£o suporta resource `vsphere_virtual_disk` separado
- **VinculaÃ§Ã£o obrigatÃ³ria**: Discos devem ser definidos dentro do bloco `vsphere_virtual_machine`
- **Simplicidade**: ConfiguraÃ§Ã£o centralizada no mesmo resource

**ImplementaÃ§Ã£o**:

```hcl
resource "vsphere_virtual_machine" "vm" {
  # Disco primÃ¡rio (obrigatÃ³rio)
  disk {
    label            = "disk0"
    size             = var.disk_size_gb
    thin_provisioned = true
  }
  
  # Discos adicionais (opcional)
  dynamic "disk" {
    for_each = var.additional_disks
    content {
      label            = disk.value.label
      size             = disk.value.size_gb
      unit_number      = disk.value.unit_number
      thin_provisioned = lookup(disk.value, "thin_provisioned", true)
    }
  }
}
```

**ConfiguraÃ§Ã£o no tfvars**:

```hcl
linux_additional_disks = [
  {
    label       = "data"
    size_gb     = 100
    unit_number = 1
  },
  {
    label       = "logs"
    size_gb     = 50
    unit_number = 2
  }
]
```

**NÃ£o criamos presets de disco**: ConfiguraÃ§Ã£o manual direta Ã© mais flexÃ­vel e suficiente.

---

### 9. **ConvenÃ§Ã£o de Nomenclatura**

**DecisÃ£o**: `<PURPOSE><ENVIRONMENT><INSTANCE>` sem hÃ­fens, uppercase.

**RazÃ£o**:

- **Limite Windows**: NetBIOS limita a 15 caracteres
- **ConsistÃªncia**: Mesmo padrÃ£o para Linux e Windows
- **Legibilidade**: Uppercase facilita identificaÃ§Ã£o
- **Paridade visual**: CPD1 Ã­mpar, CPD2 par

**Formato**:

```
<PURPOSE> = 2-6 caracteres (web, app, db, iac)
<ENVIRONMENT> = 3 caracteres (prd, qlt, tst)
<INSTANCE> = 2 dÃ­gitos (01-99)
```

**Exemplos vÃ¡lidos**:

- `IACTST01` - IAC test, instance 01 (CPD1)
- `WEBPRD02` - Web production, instance 02 (CPD2)
- `DBQLT03` - Database quality, instance 03 (CPD1)
- `APPFEPRD10` - Application FE production, instance 10 (CPD2)

**Hostname**: VersÃ£o lowercase para DNS (`iactst01.tapnet.tap.pt`)

**ValidaÃ§Ã£o**: MÃ³dulo naming verifica limite de 15 caracteres e falha se exceder.

---

### 10. **Backend Azure Storage**

**DecisÃ£o**: State armazenado em Azure Storage Account, nÃ£o local.

**RazÃ£o**:

- **ColaboraÃ§Ã£o**: MÃºltiplos usuÃ¡rios podem executar
- **State locking**: Previne execuÃ§Ãµes simultÃ¢neas
- **Backup**: State protegido em storage durÃ¡vel
- **Auditoria**: HistÃ³rico de mudanÃ§as no Azure

**ConfiguraÃ§Ã£o**:

```hcl
# backend.tf (gerado por scripts/configure.sh)
terraform {
  backend "azurerm" {
    storage_account_name = "azrprdiac01weust01"
    container_name       = "terraform-states"
    key                  = "vmware/OPS-1234.tfstate"
    use_azuread_auth     = true
  }
}
```

**OrganizaÃ§Ã£o**: Um state file por ticket (`vmware/{ticket-id}.tfstate`)

---

### 11. **Credenciais via VariÃ¡veis de Ambiente**

**DecisÃ£o**: Credenciais vSphere APENAS via variÃ¡veis de ambiente, nunca em arquivos.

**RazÃ£o**:

- **SeguranÃ§a**: Evita credenciais em Git
- **Compliance**: Atende requisitos de seguranÃ§a
- **Flexibilidade**: FÃ¡cil rotaÃ§Ã£o de credenciais
- **CI/CD ready**: Jenkins pode injetar via secrets

**VariÃ¡veis obrigatÃ³rias**:

```bash
export TF_VAR_vsphere_server="vcenterprd01.tapnet.tap.pt"
export TF_VAR_vsphere_user="vw_terraform@vsphere.local"
export TF_VAR_vsphere_password="***"
```

**ValidaÃ§Ã£o**: Scripts verificam presenÃ§a antes de executar Terraform.

---

## ğŸ“ Estrutura do Projeto

```
virtualization-automation/
â”œâ”€â”€ terraform-modules/          # MÃ³dulos Terraform reutilizÃ¡veis
â”‚   â”œâ”€â”€ naming/                 # Gera nomes padronizados de VMs
â”‚   â”‚   â”œâ”€â”€ main.tf            # LÃ³gica de nomenclatura
â”‚   â”‚   â”œâ”€â”€ variables.tf       # Inputs: purpose, environment, instance
â”‚   â”‚   â””â”€â”€ outputs.tf         # Outputs: vm_name, hostname
â”‚   â”œâ”€â”€ linux/                 # CriaÃ§Ã£o de VMs Linux
â”‚   â”‚   â”œâ”€â”€ main.tf           # Resource vsphere_virtual_machine
â”‚   â”‚   â”œâ”€â”€ variables.tf      # Inputs: cpu, memory, disk, network...
â”‚   â”‚   â””â”€â”€ outputs.tf        # Outputs: vm_id, vm_name, vm_ip...
â”‚   â””â”€â”€ windows/              # CriaÃ§Ã£o de VMs Windows
â”‚       â”œâ”€â”€ main.tf          # Resource vsphere_virtual_machine
â”‚       â”œâ”€â”€ variables.tf     # Inputs: cpu, memory, disk, admin_password...
â”‚       â””â”€â”€ outputs.tf       # Outputs: vm_id, vm_name, vm_ip...
â”‚
â”œâ”€â”€ terraform-project-template/  # Template para novos projetos
â”‚   â”œâ”€â”€ main.tf                 # OrquestraÃ§Ã£o multi-CPD
â”‚   â”œâ”€â”€ variables.tf            # Todas variÃ¡veis de config
â”‚   â”œâ”€â”€ outputs.tf              # Detalhes das VMs criadas
â”‚   â”œâ”€â”€ provider.tf             # Provider vSphere
â”‚   â”œâ”€â”€ backend.tf              # Backend Azure (gerado)
â”‚   â””â”€â”€ environments/           # Configs por ambiente
â”‚       â”œâ”€â”€ tst/
â”‚       â”‚   â””â”€â”€ terraform.tfvars
â”‚       â”œâ”€â”€ qlt/
â”‚       â”‚   â””â”€â”€ terraform.tfvars
â”‚       â””â”€â”€ prd/
â”‚           â””â”€â”€ terraform.tfvars
â”‚
â”œâ”€â”€ scripts/                    # Scripts de automaÃ§Ã£o
â”‚   â”œâ”€â”€ azure-login.sh         # AutenticaÃ§Ã£o Azure (Service Principal)
â”‚   â”œâ”€â”€ configure.sh           # Inicializar workspace
â”‚   â”œâ”€â”€ deploy.sh              # Plan e apply
â”‚   â”œâ”€â”€ destroy.sh             # Destruir infra (com safeguards)
â”‚   â”œâ”€â”€ auto-select-esx.sh     # Wrapper para seleÃ§Ã£o de ESXi
â”‚   â””â”€â”€ select-best-esx-host.py # Script Python para seleÃ§Ã£o inteligente
â”‚
â”œâ”€â”€ ansible/                    # Playbooks de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ playbooks/
â”‚   â”‚   â”œâ”€â”€ base-config.yml    # Config bÃ¡sica (timezone, chrony, motd)
â”‚   â”‚   â”œâ”€â”€ domain-join.yml    # Join AD (sssd)
â”‚   â”‚   â””â”€â”€ post-deploy.yml    # Config pÃ³s-deploy
â”‚   â””â”€â”€ templates/
â”‚       â”œâ”€â”€ chrony.conf.j2
â”‚       â”œâ”€â”€ sssd.conf.j2
â”‚       â””â”€â”€ motd.j2
â”‚
â””â”€â”€ docs/                       # DocumentaÃ§Ã£o
    â”œâ”€â”€ WORKFLOW.md            # Workflow geral
    â”œâ”€â”€ CPD-SELECTION.md       # CPD e infra
    â”œâ”€â”€ MULTI-CPD-DEPLOYMENT.md # Multi-CPD
    â”œâ”€â”€ ESX-HOST-SELECTION.md  # SeleÃ§Ã£o de ESXi
    â”œâ”€â”€ TESTE-TAP.md          # Testes na TAP
    â””â”€â”€ PROJECT-OVERVIEW.md   # Este documento
```

---

## ğŸ”„ Fluxo de Trabalho

### Workflow Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. AUTENTICAÃ‡ÃƒO AZURE                                       â”‚
â”‚    bash scripts/azure-login.sh                              â”‚
â”‚    â†’ Autentica Service Principal                            â”‚
â”‚    â†’ Valida acesso ao Storage Account                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CONFIGURAÃ‡ÃƒO DO WORKSPACE                                â”‚
â”‚    bash scripts/configure.sh OPS-1234 tst <repo-url>        â”‚
â”‚    â†’ Clona repositÃ³rio para /home/jenkins/OPS-1234          â”‚
â”‚    â†’ Gera backend.tf dinamicamente                          â”‚
â”‚    â†’ Copia terraform-modules                                â”‚
â”‚    â†’ Executa terraform init                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. CONFIGURAÃ‡ÃƒO DE VARIÃVEIS                                â”‚
â”‚    cd /home/jenkins/OPS-1234                                â”‚
â”‚    vim environments/tst/terraform.tfvars                    â”‚
â”‚    â†’ Define CPD (cpd1, cpd2, both)                          â”‚
â”‚    â†’ Define recursos (CPU, memÃ³ria, disco)                  â”‚
â”‚    â†’ Define network (IP, gateway, DNS)                      â”‚
â”‚    â†’ Define quantas VMs criar                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. EXPORTAR CREDENCIAIS VSPHERE                             â”‚
â”‚    export TF_VAR_vsphere_server="vcenterprd01..."           â”‚
â”‚    export TF_VAR_vsphere_user="vw_terraform@vsphere.local"  â”‚
â”‚    export TF_VAR_vsphere_password="***"                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. (OPCIONAL) SELEÃ‡ÃƒO AUTOMÃTICA DE ESXi                    â”‚
â”‚    export TF_VAR_vsphere_esx_host=$(                        â”‚
â”‚      bash scripts/auto-select-esx.sh CPD1_ESX7 TAP_CPD1     â”‚
â”‚    )                                                         â”‚
â”‚    â†’ Script Python consulta recursos                        â”‚
â”‚    â†’ Seleciona host com mais disponibilidade                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. DEPLOYMENT                                               â”‚
â”‚    bash scripts/deploy.sh OPS-1234 tst                      â”‚
â”‚    â†’ Gera terraform plan                                    â”‚
â”‚    â†’ Mostra mudanÃ§as para revisÃ£o                           â”‚
â”‚    â†’ Solicita confirmaÃ§Ã£o                                   â”‚
â”‚    â†’ Executa terraform apply                                â”‚
â”‚    â†’ Exibe outputs (IPs, nomes, IDs)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. CONFIGURAÃ‡ÃƒO PÃ“S-DEPLOY (Ansible)                        â”‚
â”‚    ansible-playbook -i inventory playbooks/post-deploy.yml  â”‚
â”‚    â†’ Configura timezone, chrony, motd                       â”‚
â”‚    â†’ Join domain (sssd)                                     â”‚
â”‚    â†’ Aplica hardening                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. VALIDAÃ‡ÃƒO                                                â”‚
â”‚    â†’ Verificar VMs no vCenter                               â”‚
â”‚    â†’ Testar conectividade SSH/RDP                           â”‚
â”‚    â†’ Validar nomenclatura                                   â”‚
â”‚    â†’ Verificar recursos (CPU, RAM, disco)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. (SE NECESSÃRIO) DESTRUIÃ‡ÃƒO                               â”‚
â”‚    bash scripts/destroy.sh OPS-1234 tst                     â”‚
â”‚    â†’ MÃºltiplas confirmaÃ§Ãµes                                 â”‚
â”‚    â†’ Mostra recursos a destruir                             â”‚
â”‚    â†’ Requer match do ticket-id                              â”‚
â”‚    â†’ Executa terraform destroy                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Componentes Principais

### 1. MÃ³dulo Naming

**Responsabilidade**: Gerar nomes padronizados de VMs.

**Inputs**:

- `purpose`: web, app, db, iac (2-6 chars)
- `environment`: prd, qlt, tst
- `instance_number`: 01-99 (calculado, nÃ£o variÃ¡vel)

**Outputs**:

- `vm_name`: Nome uppercase (ex: WEBPRD01)
- `hostname`: Nome lowercase para DNS (ex: webprd01)

**LÃ³gica**:

```hcl
vm_name = "${upper(var.purpose)}${upper(var.environment)}${format("%02d", var.instance_number)}"
hostname = lower(local.vm_name)
```

**ValidaÃ§Ã£o**: Falha se nome exceder 15 caracteres (limite NetBIOS).

---

### 2. MÃ³dulo Linux

**Responsabilidade**: Criar VMs Linux sem template.

**Features**:

- âœ… Sem data source de template
- âœ… Usa `guest_id` (rhel9_64Guest)
- âœ… Network adapter configurÃ¡vel (vmxnet3 padrÃ£o)
- âœ… Suporte a ESXi host especÃ­fico
- âœ… Disco primÃ¡rio + discos adicionais
- âœ… CustomizaÃ§Ã£o de network (IP, gateway, DNS)
- âœ… Tags incluindo CPD e Sequence

**Resource principal**:

```hcl
resource "vsphere_virtual_machine" "vm" {
  name             = var.vm_name
  resource_pool_id = local.resource_pool_id
  datastore_id     = data.vsphere_datastore.datastore.id
  host_system_id   = var.esx_host != null ? data.vsphere_host.esx[0].id : null
  
  num_cpus = var.cpu_count
  memory   = var.memory_mb
  guest_id = var.guest_id  # rhel9_64Guest
  
  network_interface {
    network_id   = data.vsphere_network.network.id
    adapter_type = var.network_adapter_type
  }
  
  disk {
    label = "disk0"
    size  = var.disk_size_gb
  }
  
  dynamic "disk" {
    for_each = var.additional_disks
    content { ... }
  }
}
```

---

### 3. MÃ³dulo Windows

**Responsabilidade**: Criar VMs Windows sem template.

**Features**:

- âœ… Similar ao mÃ³dulo Linux
- âœ… Usa `windows2019srvNext_64Guest` ou `windows2022srvNext_64Guest`
- âœ… ConfiguraÃ§Ã£o de admin password
- âœ… Workgroup ou domain join
- âœ… Auto logon opcional
- âœ… Timezone configurÃ¡vel

**DiferenÃ§as do Linux**:

- `customize` block diferente (Windows sysprep)
- VariÃ¡veis adicionais: `admin_password`, `workgroup`, `timezone`, `auto_logon`

---

### 4. Project Template - Main.tf

**Responsabilidade**: Orquestrar deployment multi-CPD de mÃºltiplas VMs.

**LÃ³gica principal**:

1. **Determinar CPDs alvo**:

```hcl
target_cpds = var.cpd == "both" ? ["cpd1", "cpd2"] : [var.cpd]
```

1. **Criar mapa de VMs**:

```hcl
linux_vms = {
  for item in flatten([
    for cpd in local.target_cpds : [
      for idx in range(var.linux_vm_count) : {
        cpd      = cpd
        sequence = var.linux_vm_start_sequence + idx
        vm_index = idx
      }
    ]
  ]) : "${item.cpd}-${item.sequence}" => item
}
```

1. **Chamar mÃ³dulo naming para cada VM**:

```hcl
module "linux_naming" {
  for_each = local.linux_vms
  
  instance_number = each.value.cpd == "cpd1" ? 
    (each.value.sequence * 2 - 1) : 
    (each.value.sequence * 2)
}
```

1. **Chamar mÃ³dulo VM para cada instÃ¢ncia**:

```hcl
module "linux_vm" {
  for_each = local.linux_vms
  
  vm_name = module.linux_naming[each.key].vm_name
  datacenter = coalesce(var.vsphere_datacenter, local.cpd_config[each.value.cpd].datacenter)
  ...
}
```

---

### 5. Scripts Shell

#### azure-login.sh

**PropÃ³sito**: Autenticar Azure Service Principal.

**VariÃ¡veis obrigatÃ³rias**:

- `ARM_CLIENT_ID`: Application (client) ID
- `ARM_CLIENT_SECRET`: Client secret
- `ARM_TENANT_ID`: Directory (tenant) ID
- `ARM_SUBSCRIPTION_ID`: Subscription ID

**ExecuÃ§Ã£o**:

```bash
bash scripts/azure-login.sh
```

---

#### configure.sh

**PropÃ³sito**: Inicializar workspace de projeto.

**ParÃ¢metros**:

```bash
bash scripts/configure.sh <ticket-id> <environment> <git-repo-url>
```

**AÃ§Ãµes**:

1. Valida parÃ¢metros
2. Clona repositÃ³rio Git para `/home/jenkins/{ticket-id}`
3. Gera `backend.tf` com configuraÃ§Ã£o Azure
4. Copia `terraform-modules` do repo
5. Executa `terraform init`

**Exemplo**:

```bash
bash scripts/configure.sh OPS-1234 tst https://github.com/tap/virtualization-automation.git
```

---

#### deploy.sh

**PropÃ³sito**: Planejar e aplicar mudanÃ§as Terraform.

**ParÃ¢metros**:

```bash
bash scripts/deploy.sh <ticket-id> <environment>
```

**AÃ§Ãµes**:

1. Valida credenciais vSphere
2. Muda para workspace directory
3. Gera plan: `terraform plan -var-file=environments/{env}/terraform.tfvars`
4. Mostra plan para revisÃ£o
5. Solicita confirmaÃ§Ã£o (yes/no)
6. Aplica: `terraform apply tfplan-{env}.out`
7. Exibe outputs

**Exemplo**:

```bash
bash scripts/deploy.sh OPS-1234 tst
```

---

#### destroy.sh

**PropÃ³sito**: Destruir infraestrutura com seguranÃ§a mÃ¡xima.

**ParÃ¢metros**:

```bash
bash scripts/destroy.sh <ticket-id> <environment>
```

**Safeguards**:

1. âš ï¸ MÃºltiplas confirmaÃ§Ãµes
2. âš ï¸ Mostra recursos a destruir
3. âš ï¸ Requer digitaÃ§Ã£o do ticket-id para confirmar
4. âš ï¸ Logging de todas aÃ§Ãµes
5. âš ï¸ NÃ£o permite destroy em produÃ§Ã£o sem override

**Exemplo**:

```bash
bash scripts/destroy.sh OPS-1234 tst
# Pergunta: "Are you sure? (yes/no)"
# Mostra recursos
# Pergunta: "Type ticket-id to confirm: "
# Requer: "OPS-1234"
```

---

#### auto-select-esx.sh

**PropÃ³sito**: Wrapper Bash para script Python de seleÃ§Ã£o de ESXi.

**ParÃ¢metros**:

```bash
bash scripts/auto-select-esx.sh <cluster> <datacenter> [metric]
```

**ValidaÃ§Ãµes**:

- âœ… Verifica se Python 3 estÃ¡ instalado
- âœ… Verifica se pyvmomi estÃ¡ instalado
- âœ… Verifica credenciais vSphere
- âœ… Fallback gracioso: Retorna vazio (DRS decide) se falhar

**Uso**:

```bash
export TF_VAR_vsphere_esx_host=$(bash scripts/auto-select-esx.sh CPD1_ESX7 TAP_CPD1)
```

---

#### select-best-esx-host.py

**PropÃ³sito**: Consultar recursos de ESXi hosts e selecionar o melhor.

**DependÃªncias**: `pip3 install pyvmomi`

**ParÃ¢metros**:

```bash
python3 scripts/select-best-esx-host.py \
  --datacenter TAP_CPD1 \
  --cluster CPD1_ESX7 \
  --metric balanced \
  --format fqdn
```

**MÃ©tricas disponÃ­veis**:

- `cpu`: Seleciona host com mais CPU disponÃ­vel (MHz)
- `memory`: Seleciona host com mais memÃ³ria disponÃ­vel (MB)
- `balanced`: Seleciona balanceamento entre CPU e memÃ³ria (padrÃ£o)

**Formatos de saÃ­da**:

- `fqdn`: Retorna apenas FQDN do host (ex: esxprd109.tapnet.tap.pt)
- `json`: Retorna JSON com detalhes completos

**Filtros aplicados**:

- âœ… Host must be connected
- âœ… Host must be powered on
- âœ… Host must NOT be in maintenance mode

---

## âš™ï¸ ConfiguraÃ§Ã£o e Uso

### PrÃ©-requisitos

1. **Software**:
   - Terraform >= 1.5.0
   - Azure CLI
   - Git
   - Python 3 (para auto-select ESXi)
   - pip3 install pyvmomi (para auto-select ESXi)

2. **Credenciais Azure**:

   ```bash
   export ARM_CLIENT_ID="..."
   export ARM_CLIENT_SECRET="..."
   export ARM_TENANT_ID="..."
   export ARM_SUBSCRIPTION_ID="..."
   ```

3. **Credenciais vSphere**:

   ```bash
   export TF_VAR_vsphere_server="vcenterprd01.tapnet.tap.pt"
   export TF_VAR_vsphere_user="vw_terraform@vsphere.local"
   export TF_VAR_vsphere_password="***"
   ```

---

### ConfiguraÃ§Ã£o BÃ¡sica (CPD1, 1 VM Linux)

**terraform.tfvars**:

```hcl
# Projeto
environment    = "tst"
project_name   = "test-automation"
ticket_id      = "OPS-1234"

# CPD
cpd = "cpd1"

# Linux VM
create_linux_vm         = true
linux_vm_purpose        = "iac"
linux_vm_count          = 1
linux_vm_start_sequence = 1
linux_cpu_count         = 2
linux_memory_mb         = 4096
linux_disk_size_gb      = 50
linux_guest_id          = "rhel9_64Guest"

# Network
network_domain      = "tapnet.tap.pt"
linux_ipv4_address  = "10.190.10.10"
network_ipv4_gateway = "10.190.10.1"
network_ipv4_netmask = 24
network_dns_servers  = ["10.190.1.10", "10.190.1.11"]

# vSphere (usa defaults)
vsphere_datastore = "PS04_ESX2_CPDMIG"
vsphere_folder    = "TerraformTests"
```

**Resultado**: Cria VM `IACTST01` no CPD1.

---

### ConfiguraÃ§Ã£o Multi-CPD (2 VMs em cada CPD)

**terraform.tfvars**:

```hcl
# CPD
cpd = "both"  # â† Multi-CPD

# Linux VM
create_linux_vm         = true
linux_vm_purpose        = "web"
linux_vm_count          = 2  # â† 2 VMs por CPD
linux_vm_start_sequence = 1
# ... resto igual
```

**Resultado**: Cria 4 VMs:

- CPD1: `WEBTST01`, `WEBTST03`
- CPD2: `WEBTST02`, `WEBTST04`

---

### ConfiguraÃ§Ã£o com MÃºltiplas VMs e Discos Adicionais

**terraform.tfvars**:

```hcl
# CPD
cpd = "cpd1"

# Linux VM
create_linux_vm         = true
linux_vm_purpose        = "db"
linux_vm_count          = 3  # â† 3 VMs
linux_vm_start_sequence = 5  # â† ComeÃ§a na sequÃªncia 5
linux_cpu_count         = 4
linux_memory_mb         = 8192
linux_disk_size_gb      = 100

# Discos adicionais
linux_additional_disks = [
  {
    label       = "data"
    size_gb     = 500
    unit_number = 1
  },
  {
    label       = "logs"
    size_gb     = 100
    unit_number = 2
  }
]
# ... network config
```

**Resultado**: Cria 3 VMs no CPD1:

- `DBTST09` (sequence 5, instance 09)
- `DBTST11` (sequence 6, instance 11)
- `DBTST13` (sequence 7, instance 13)

Cada uma com:

- Disco primÃ¡rio: 100 GB
- Disco data: 500 GB
- Disco logs: 100 GB

---

### ConfiguraÃ§Ã£o com ESXi EspecÃ­fico

**terraform.tfvars**:

```hcl
# vSphere
vsphere_esx_host = "esxprd109.tapnet.tap.pt"  # â† Host especÃ­fico
```

Ou via script antes do deploy:

```bash
export TF_VAR_vsphere_esx_host=$(bash scripts/auto-select-esx.sh CPD1_ESX7 TAP_CPD1)
bash scripts/deploy.sh OPS-1234 tst
```

---

## ğŸ“š Casos de Uso

### Caso 1: Single VM de Teste em CPD1

**Objetivo**: Criar uma VM Linux simples para testes.

**ConfiguraÃ§Ã£o**:

```hcl
cpd                     = "cpd1"
linux_vm_count          = 1
linux_vm_start_sequence = 1
linux_vm_purpose        = "test"
environment             = "tst"
```

**ExecuÃ§Ã£o**:

```bash
bash scripts/configure.sh OPS-1234 tst https://...
export TF_VAR_vsphere_*
bash scripts/deploy.sh OPS-1234 tst
```

**Resultado**: VM `TESTTST01` criada no CPD1.

---

### Caso 2: Par HA Web Servers (CPD1 + CPD2)

**Objetivo**: Criar servidores web redundantes em ambos CPDs.

**ConfiguraÃ§Ã£o**:

```hcl
cpd                     = "both"  # â† Ambos CPDs
linux_vm_count          = 1       # â† 1 por CPD = 2 total
linux_vm_start_sequence = 1
linux_vm_purpose        = "web"
environment             = "prd"
linux_cpu_count         = 4
linux_memory_mb         = 8192
```

**ExecuÃ§Ã£o**: Similar ao Caso 1.

**Resultado**:

- CPD1: `WEBPRD01`
- CPD2: `WEBPRD02`

Par de VMs com mesma configuraÃ§Ã£o em datacenters diferentes.

---

### Caso 3: Cluster Database (3 nodes em CPD1)

**Objetivo**: Criar cluster de banco de dados com 3 nodes.

**ConfiguraÃ§Ã£o**:

```hcl
cpd                     = "cpd1"
linux_vm_count          = 3       # â† 3 VMs
linux_vm_start_sequence = 1
linux_vm_purpose        = "db"
environment             = "prd"
linux_cpu_count         = 8
linux_memory_mb         = 32768
linux_disk_size_gb      = 200

linux_additional_disks = [
  { label = "data", size_gb = 1000, unit_number = 1 },
  { label = "logs", size_gb = 200, unit_number = 2 },
  { label = "backup", size_gb = 500, unit_number = 3 }
]
```

**Resultado**:

- `DBPRD01` (sequence 1, instance 01)
- `DBPRD03` (sequence 2, instance 03)
- `DBPRD05` (sequence 3, instance 05)

Cada uma com 4 discos (primary + 3 adicionais).

---

### Caso 4: ExpansÃ£o de Ambiente Existente

**Objetivo**: Adicionar mais VMs a um ambiente existente sem recriar as atuais.

**Estado atual**: JÃ¡ existem VMs com sequences 1-5.

**Nova configuraÃ§Ã£o**:

```hcl
cpd                     = "cpd1"
linux_vm_count          = 2       # â† Mais 2 VMs
linux_vm_start_sequence = 6       # â† ComeÃ§a na 6
linux_vm_purpose        = "app"
environment             = "prd"
```

**Resultado**:

- `APPPRD11` (sequence 6, instance 11)
- `APPPRD13` (sequence 7, instance 13)

**Por que for_each Ã© importante aqui**:

- Novas VMs tÃªm keys `cpd1-6` e `cpd1-7`
- VMs existentes (`cpd1-1` a `cpd1-5`) nÃ£o sÃ£o afetadas
- Se fosse `count`, adicionar VMs recriaria recursos

---

### Caso 5: MigraÃ§Ã£o entre CPDs

**Objetivo**: Criar rÃ©plica em CPD2 de VMs existentes em CPD1.

**Config original (CPD1)**:

```hcl
cpd                     = "cpd1"
linux_vm_count          = 2
linux_vm_start_sequence = 1
```

Resultado: `APPPRD01`, `APPPRD03`

**Nova config (ambos CPDs)**:

```hcl
cpd                     = "both"  # â† Adiciona CPD2
linux_vm_count          = 2
linux_vm_start_sequence = 1
```

Resultado adicional: `APPPRD02`, `APPPRD04` no CPD2

**Importante**: CPD1 VMs nÃ£o sÃ£o recriadas (for_each preserva).

---

### Caso 6: DestruiÃ§Ã£o Seletiva

**Objetivo**: Remover VM especÃ­fica sem afetar outras.

**Comando**:

```bash
cd /home/jenkins/OPS-1234
terraform destroy -target='module.linux_vm["cpd1-3"]'
```

**Resultado**: Apenas VM com sequence 3 no CPD1 Ã© destruÃ­da.

**Alternativa**: Modificar tfvars para excluir e re-apply (nÃ£o recomendado).

---

## ğŸ“ Resumo Executivo

### O que este projeto resolve?

1. âœ… **AutomaÃ§Ã£o completa**: Do clone do repo atÃ© VMs configuradas
2. âœ… **Sem templates**: VMs criadas do zero, configuradas via Ansible
3. âœ… **Multi-datacenter**: Suporte nativo para CPD1, CPD2 ou ambos
4. âœ… **Nomenclatura consistente**: Sem conflitos, paridade automÃ¡tica
5. âœ… **Escalabilidade**: Criar 1 ou mÃºltiplas VMs com mesma config
6. âœ… **Flexibilidade**: DRS automÃ¡tico ou seleÃ§Ã£o manual/inteligente de ESXi
7. âœ… **SeguranÃ§a**: Credenciais via env vars, state remoto, mÃºltiplas confirmaÃ§Ãµes
8. âœ… **Rastreabilidade**: Um state por ticket, logging completo

### Quando usar?

- âœ… Criar VMs para novos projetos
- âœ… Provisionar ambientes completos (dev, qlt, prd)
- âœ… Replicar configuraÃ§Ã£o entre datacenters
- âœ… Expandir ambientes existentes
- âœ… Testes de automaÃ§Ã£o
- âœ… Disaster recovery (criar rÃ©plicas)

### Quando NÃƒO usar?

- âŒ VMs Ãºnicas pontuais (pode usar vCenter UI)
- âŒ MudanÃ§as em VMs existentes nÃ£o gerenciadas por Terraform
- âŒ Ambientes fora da TAP (requer adaptaÃ§Ã£o)

---

## ğŸš€ PrÃ³ximos Passos para POC

1. **PreparaÃ§Ã£o**:

   ```bash
   # Clonar repositÃ³rio
   git clone https://github.com/tap/virtualization-automation.git
   cd virtualization-automation
   
   # Autenticar Azure
   export ARM_CLIENT_ID="..."
   export ARM_CLIENT_SECRET="..."
   export ARM_TENANT_ID="..."
   export ARM_SUBSCRIPTION_ID="..."
   bash scripts/azure-login.sh
   ```

2. **ConfiguraÃ§Ã£o**:

   ```bash
   # Inicializar workspace
   bash scripts/configure.sh OPS-POC-001 tst https://github.com/tap/virtualization-automation.git
   
   # Editar variÃ¡veis
   cd /home/jenkins/OPS-POC-001
   vim environments/tst/terraform.tfvars
   ```

3. **Deploy**:

   ```bash
   # Exportar credenciais vSphere
   export TF_VAR_vsphere_server="vcenterprd01.tapnet.tap.pt"
   export TF_VAR_vsphere_user="vw_terraform@vsphere.local"
   export TF_VAR_vsphere_password="***"
   
   # Executar deployment
   bash scripts/deploy.sh OPS-POC-001 tst
   ```

4. **ValidaÃ§Ã£o**:
   - Verificar VM no vCenter: `IACTST01` existe?
   - Nome estÃ¡ correto?
   - CPD1 ou CPD2 conforme configurado?
   - Recursos (CPU, memÃ³ria, disco) corretos?
   - Network configurada?

5. **Limpeza**:

   ```bash
   bash scripts/destroy.sh OPS-POC-001 tst
   ```

---

## ğŸ“ Suporte e Troubleshooting

### Erros Comuns

1. **"Failed to authenticate with Azure"**:
   - Verificar variÃ¡veis `ARM_*`
   - Re-executar `azure-login.sh`

2. **"Failed to connect to vCenter"**:
   - Verificar variÃ¡veis `TF_VAR_vsphere_*`
   - Testar conectividade: `ping vcenterprd01.tapnet.tap.pt`
   - Validar credenciais no vCenter UI

3. **"VM name exceeds 15 characters"**:
   - Reduzir `purpose` (ex: `webapp` â†’ `web`)
   - Verificar: `<PURPOSE><ENV><INSTANCE>` â‰¤ 15 chars

4. **"No hosts found in cluster"**:
   - Verificar nome do cluster: `CPD1_ESX7` (case-sensitive)
   - Verificar nome do datacenter: `TAP_CPD1`

5. **"State lock timeout"**:
   - Outra execuÃ§Ã£o em andamento
   - Aguardar ou forÃ§ar unlock (com cuidado)

---

## ğŸ“ ConclusÃ£o

Este projeto fornece uma soluÃ§Ã£o completa, flexÃ­vel e segura para automaÃ§Ã£o de infraestrutura VMware. As decisÃµes arquiteturais foram tomadas para:

- âœ… **Simplicidade**: Sem templates, auto-cÃ¡lculo de instÃ¢ncias
- âœ… **ConsistÃªncia**: CPD define tudo, nomenclatura padronizada
- âœ… **EficiÃªncia**: Multi-VM, multi-CPD em uma execuÃ§Ã£o
- âœ… **SeguranÃ§a**: Credenciais via env vars, mÃºltiplas confirmaÃ§Ãµes
- âœ… **Manutenibilidade**: MÃ³dulos reutilizÃ¡veis, for_each flexÃ­vel

A POC vai validar todos esses conceitos no ambiente real da TAP.

---

**Documento criado em**: $(date)  
**VersÃ£o**: 1.0  
**Autor**: AutomaÃ§Ã£o TAP  
**Status**: Pronto para POC
